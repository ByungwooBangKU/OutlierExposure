#!/usr/bin/env python3
"""
ì¶”ê°€ ì‹¤í—˜ íŒŒë¼ë¯¸í„° ì œì•ˆ ë¶„ì„

í˜„ì¬ ì‹¤í—˜ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ê³„ ì‹¤í—˜ì„ ìœ„í•œ íŒŒë¼ë¯¸í„° ë²”ìœ„ ì œì•ˆ
"""

import pandas as pd
import numpy as np

# ë°ì´í„° ë¡œë“œ
df = pd.read_csv('wandb_self_oe_results.csv')

print("="*80)
print("í˜„ì¬ ì‹¤í—˜ íŒŒë¼ë¯¸í„° ë¶„ì„ ë° ì¶”ê°€ ì‹¤í—˜ ì œì•ˆ")
print("="*80)

# 1. í˜„ì¬ ì‹¤í—˜ëœ íŒŒë¼ë¯¸í„° í™•ì¸
print("\nã€í˜„ì¬ ì‹¤í—˜ëœ íŒŒë¼ë¯¸í„° ë²”ìœ„ã€‘")
print("-"*80)
print(f"attention_top_p: {sorted(df['attention_top_p'].unique())}")
print(f"masking_probability: {sorted(df['masking_probability'].unique())}")
print(f"attention_filtering_method: {sorted(df['attention_filtering_method'].unique())}")

# 2. ì„±ëŠ¥ ë¶„ì„
print("\nã€ì„±ëŠ¥ ë¶„ì„ ìš”ì•½ã€‘")
print("-"*80)
print(f"ìµœê³  AUROC: {df['auroc_mean'].max():.4f}")
print(f"í‰ê·  AUROC: {df['auroc_mean'].mean():.4f} Â± {df['auroc_mean'].std():.4f}")

# Masking íš¨ê³¼
mask_0 = df[df['masking_probability'] == 0.00]['auroc_mean'].mean()
mask_5 = df[df['masking_probability'] == 0.05]['auroc_mean'].mean()
print(f"\nMasking 0.00: {mask_0:.4f}")
print(f"Masking 0.05: {mask_5:.4f} (ê°œì„ : +{(mask_5-mask_0)/mask_0*100:.2f}%)")

# Top-p íš¨ê³¼
top_p_stats = df.groupby('attention_top_p')['auroc_mean'].agg(['mean', 'std'])
print(f"\nTop-pë³„ ì„±ëŠ¥:")
for idx, row in top_p_stats.iterrows():
    print(f"  {idx:.2f}: {row['mean']:.4f} Â± {row['std']:.4f}")

# Filtering method íš¨ê³¼
filter_stats = df.groupby('attention_filtering_method')['auroc_mean'].agg(['mean', 'std', 'count'])
filter_stats = filter_stats.sort_values('mean', ascending=False)
print(f"\nFiltering Methodë³„ ì„±ëŠ¥ (ìƒìœ„ 3ê°œ):")
for idx, row in filter_stats.head(3).iterrows():
    print(f"  {idx}: {row['mean']:.4f} Â± {row['std']:.4f} (n={int(row['count'])})")

# 3. ì¶”ê°€ ì‹¤í—˜ ì œì•ˆ
print("\n\n" + "="*80)
print("ã€ì¶”ê°€ ì‹¤í—˜ íŒŒë¼ë¯¸í„° ì œì•ˆã€‘")
print("="*80)

recommendations = []

# ì œì•ˆ 1: Masking Probability ì„¸ë°€í™”
print("\n1ï¸âƒ£  Masking Probability ì„¸ë°€í™” (Fine-tuning around optimal)")
print("-"*80)
print("í˜„ì¬: 0.00, 0.05 â†’ 0.05ê°€ +4.15% ìš°ìˆ˜")
print("ì œì•ˆ: 0.05 ì£¼ë³€ ì„¸ë°€ íƒìƒ‰ìœ¼ë¡œ ìµœì ê°’ ì°¾ê¸°")
print()
print("  --masking_probabilities 0.03,0.04,0.05,0.06,0.07,0.08")
print()
print("ê·¼ê±°:")
print("  â€¢ Masking 0.05ê°€ í†µê³„ì ìœ¼ë¡œ ë§¤ìš° ìœ ì˜ë¯¸í•˜ê²Œ ìš°ìˆ˜ (p<0.001)")
print("  â€¢ 0.05 ì£¼ë³€ ê°’ìœ¼ë¡œ ë” ì¢‹ì€ ì„±ëŠ¥ ê°€ëŠ¥ì„±")
print("  â€¢ 0.03~0.08 ë²”ìœ„ë¡œ ìµœì  sweet spot íƒìƒ‰")

recommendations.append({
    'name': 'Masking Fine-tuning',
    'param': '--masking_probabilities',
    'values': '0.03,0.04,0.05,0.06,0.07,0.08',
    'priority': 'HIGH',
    'expected_gain': '0.5-1.0% AUROC ì¶”ê°€ ê°œì„  ê°€ëŠ¥'
})

# ì œì•ˆ 2: Attention Top-p í™•ì¥
print("\n\n2ï¸âƒ£  Attention Top-p í™•ì¥ (Broader exploration)")
print("-"*80)
print("í˜„ì¬: 0.15, 0.25, 0.35 â†’ 0.25ê°€ ìµœì  (ì°¨ì´ ì‘ìŒ)")
print("ì œì•ˆ: ë” ë„“ì€ ë²”ìœ„ + ìµœì ê°’ ì£¼ë³€ ì„¸ë°€í™”")
print()
print("  ì˜µì…˜ A (ë„“ì€ ë²”ìœ„): --attention_top_p_values 0.10,0.20,0.30,0.40,0.50")
print("  ì˜µì…˜ B (ì„¸ë°€í™”):   --attention_top_p_values 0.20,0.22,0.24,0.26,0.28,0.30")
print()
print("ê·¼ê±°:")
print("  â€¢ í˜„ì¬ top-p ê°„ ì°¨ì´ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ì§€ ì•ŠìŒ (p=0.362)")
print("  â€¢ ë” ë„“ì€ ë²”ìœ„ íƒìƒ‰ìœ¼ë¡œ ë¹„ì„ í˜• íš¨ê³¼ í™•ì¸ í•„ìš”")
print("  â€¢ ë˜ëŠ” 0.25 ì£¼ë³€ ì„¸ë°€ íƒìƒ‰ìœ¼ë¡œ ë¯¸ì„¸ ìµœì í™”")

recommendations.append({
    'name': 'Top-p Exploration',
    'param': '--attention_top_p_values',
    'values': '0.10,0.20,0.30,0.40,0.50 (ë˜ëŠ” 0.20,0.22,0.24,0.26,0.28,0.30)',
    'priority': 'MEDIUM',
    'expected_gain': 'í˜„ì¬ robustí•˜ë¯€ë¡œ í° ê°œì„  ì–´ë ¤ì›€, ì•ˆì •ì„± í™•ì¸ ëª©ì '
})

# ì œì•ˆ 3: Attention Stages ë³€ê²½
print("\n\n3ï¸âƒ£  Attention Stages í™•ì¥ (Stage exploration)")
print("-"*80)
print("í˜„ì¬: stage2ë§Œ ì‹¤í—˜")
print("ì œì•ˆ: stage3, both ì¶”ê°€ ì‹¤í—˜")
print()
print("  --attention_stages stage2,stage3,both")
print()
print("ê·¼ê±°:")
print("  â€¢ Stage2ëŠ” attention cache ìƒì„± ë‹¨ê³„")
print("  â€¢ Stage3ëŠ” ì‹¤ì œ OE í•™ìŠµ ë‹¨ê³„ - ì„±ëŠ¥ ì°¨ì´ ê°€ëŠ¥ì„±")
print("  â€¢ BothëŠ” stage2+stage3 ë™ì‹œ ìˆ˜í–‰")
print("  â€¢ ê° stageë³„ ìµœì  íŒŒë¼ë¯¸í„°ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ")

recommendations.append({
    'name': 'Stage Exploration',
    'param': '--attention_stages',
    'values': 'stage2,stage3,both',
    'priority': 'HIGH',
    'expected_gain': 'Stageë³„ íŠ¹ì„±ì— ë”°ë¼ 1-2% ê°œì„  ê°€ëŠ¥'
})

# ì œì•ˆ 4: Loss Weights ì¡°ì •
print("\n\n4ï¸âƒ£  Loss Weights ì¡°ì • (Loss balancing)")
print("-"*80)
print("í˜„ì¬: oe_uniform_loss_weight=1.0, self_attention_loss_weight=1.0 (ê³ ì •)")
print("ì œì•ˆ: Loss weight ë¹„ìœ¨ ì¡°ì •ìœ¼ë¡œ ê· í˜• íƒìƒ‰")
print()
print("  --oe_uniform_loss_weights 0.5,1.0,1.5,2.0")
print("  --self_attention_loss_weights 0.5,1.0,1.5,2.0")
print()
print("ê·¼ê±°:")
print("  â€¢ ID classificationê³¼ OE loss ê°„ ê· í˜• ì¤‘ìš”")
print("  â€¢ HendrycksëŠ” Î»=1.0 ì‚¬ìš©í–ˆì§€ë§Œ, Self-OEëŠ” ë‹¤ë¥¼ ìˆ˜ ìˆìŒ")
print("  â€¢ 0.5~2.0 ë²”ìœ„ë¡œ ìµœì  ë¹„ìœ¨ íƒìƒ‰")

recommendations.append({
    'name': 'Loss Weight Tuning',
    'param': '--oe_uniform_loss_weights, --self_attention_loss_weights',
    'values': '0.5,1.0,1.5,2.0 (ê°ê°)',
    'priority': 'MEDIUM',
    'expected_gain': '0.5-1.5% AUROC ê°œì„  ê°€ëŠ¥'
})

# ì œì•ˆ 5: Attention Top-k ì‹¤í—˜
print("\n\n5ï¸âƒ£  Attention Top-k ê°’ ë„ì… (Top-k filtering)")
print("-"*80)
print("í˜„ì¬: top-k=None (ì‚¬ìš© ì•ˆ í•¨)")
print("ì œì•ˆ: Top-k ê°’ ë„ì…ìœ¼ë¡œ í† í° ì„ íƒ ê°•í™”")
print()
print("  --attention_top_k_values 3,5,10,20,50")
print()
print("ê·¼ê±°:")
print("  â€¢ Top-pë§Œìœ¼ë¡œëŠ” ë„ˆë¬´ ë§ì€/ì ì€ í† í° ì„ íƒ ê°€ëŠ¥")
print("  â€¢ Top-kë¡œ ì„ íƒ í† í° ìˆ˜ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì œí•œ")
print("  â€¢ ì‘ì€ k (3-10): í•µì‹¬ í† í°ë§Œ, í° k (20-50): ë„“ì€ ë²”ìœ„")

recommendations.append({
    'name': 'Top-k Introduction',
    'param': '--attention_top_k_values',
    'values': '3,5,10,20,50',
    'priority': 'MEDIUM-HIGH',
    'expected_gain': '1-2% AUROC ê°œì„  ê°€ëŠ¥ (í•µì‹¬ í† í° íƒ€ê²ŸíŒ…)'
})

# ì œì•ˆ 6: ìµœê³  ì„±ëŠ¥ ì¡°í•© Ablation Study
print("\n\n6ï¸âƒ£  ìµœê³  ì„±ëŠ¥ ì¡°í•© ì£¼ë³€ Ablation Study")
print("-"*80)
print(f"í˜„ì¬ ìµœê³  ì„±ëŠ¥: AUROC 0.8264")
print("  - top-p=0.25, masking=0.05, top_k_avg_elbow_lower")
print()
print("ì œì•ˆ: ìµœê³  ì„±ëŠ¥ ì¡°í•© ì£¼ë³€ ì§‘ì¤‘ íƒìƒ‰")
print()
print("  --attention_top_p_values 0.23,0.25,0.27")
print("  --masking_probabilities 0.04,0.05,0.06")
print("  --attention_filtering_methodë§Œ top_k_avg_elbow_lowerë¡œ ê³ ì •")
print()
print("ê·¼ê±°:")
print("  â€¢ ìµœê³  ì„±ëŠ¥ ì¡°í•© ì£¼ë³€ì— ë” ì¢‹ì€ ì ì´ ìˆì„ ê°€ëŠ¥ì„±")
print("  â€¢ ê³„ì‚° ë¹„ìš© ì ˆê° (í•œ ê°€ì§€ filteringë§Œ)")
print("  â€¢ ë¯¸ì„¸ ìµœì í™”ë¡œ 0.83+ AUROC ë‹¬ì„± ê°€ëŠ¥ì„±")

recommendations.append({
    'name': 'Best Config Ablation',
    'param': '--attention_top_p_values, --masking_probabilities',
    'values': '0.23,0.25,0.27 / 0.04,0.05,0.06',
    'priority': 'HIGH',
    'expected_gain': '0.5-1.0% AUROC ì¶”ê°€ ê°œì„  â†’ 0.83+ ë‹¬ì„± ê°€ëŠ¥'
})

# ì œì•ˆ 7: Epoch ìˆ˜ ì¦ê°€
print("\n\n7ï¸âƒ£  Training Epochs ì¦ê°€ (Longer training)")
print("-"*80)
print("í˜„ì¬: num_epochs=5")
print("ì œì•ˆ: í•™ìŠµ ì—í­ ì¦ê°€ë¡œ ìˆ˜ë ´ í™•ì¸")
print()
print("  --num_epochs 7 (ë˜ëŠ” 10)")
print()
print("ê·¼ê±°:")
print("  â€¢ 5 epochì—ì„œ underfitting ê°€ëŠ¥ì„±")
print("  â€¢ ë” ê¸´ í•™ìŠµìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ ì—¬ë¶€ í™•ì¸")
print("  â€¢ Early stopping ìˆìœ¼ë¯€ë¡œ overfitting ìœ„í—˜ ë‚®ìŒ")

recommendations.append({
    'name': 'Longer Training',
    'param': '--num_epochs',
    'values': '7 or 10',
    'priority': 'LOW-MEDIUM',
    'expected_gain': '0.3-0.7% AUROC ê°œì„  ê°€ëŠ¥ (ìˆ˜ë ´ ì—¬ë¶€ì— ë”°ë¼)'
})

# ì œì•ˆ ìš”ì•½ í…Œì´ë¸”
print("\n\n" + "="*80)
print("ã€ì¶”ê°€ ì‹¤í—˜ ìš°ì„ ìˆœìœ„ ìš”ì•½ã€‘")
print("="*80)

print("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
print("â”‚ ìš°ì„ ìˆœìœ„ â”‚ ì‹¤í—˜ëª…                     â”‚ ê¸°ëŒ€ íš¨ê³¼                          â”‚")
print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
print("â”‚ HIGH     â”‚ 1. Masking Fine-tuning     â”‚ 0.5-1.0% AUROC ì¶”ê°€ ê°œì„           â”‚")
print("â”‚ HIGH     â”‚ 3. Stage Exploration       â”‚ 1-2% AUROC ê°œì„  (stageë³„ íŠ¹ì„±)    â”‚")
print("â”‚ HIGH     â”‚ 6. Best Config Ablation    â”‚ 0.5-1.0% ê°œì„  â†’ 0.83+ ë‹¬ì„± ê°€ëŠ¥   â”‚")
print("â”‚ MED-HIGH â”‚ 5. Top-k Introduction      â”‚ 1-2% AUROC ê°œì„  (í•µì‹¬ í† í°)       â”‚")
print("â”‚ MEDIUM   â”‚ 2. Top-p Exploration       â”‚ ì•ˆì •ì„± í™•ì¸ (í° ê°œì„  ì–´ë ¤ì›€)      â”‚")
print("â”‚ MEDIUM   â”‚ 4. Loss Weight Tuning      â”‚ 0.5-1.5% AUROC ê°œì„                â”‚")
print("â”‚ LOW-MED  â”‚ 7. Longer Training         â”‚ 0.3-0.7% AUROC ê°œì„                â”‚")
print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

# êµ¬ì²´ì  ëª…ë ¹ì–´ ì˜ˆì‹œ
print("\n\n" + "="*80)
print("ã€ì¶”ì²œ ì‹¤í—˜ ëª…ë ¹ì–´ã€‘")
print("="*80)

print("\nâœ… ì‹¤í—˜ ì„¸íŠ¸ 1: ìµœìš°ì„  ì‹¤í—˜ (Best Config Ablation + Masking Fine-tuning)")
print("-"*80)
cmd1 = """python scripts/run_oe_sweep.py \\
  --dataset 20newsgroups \\
  --mode self_attention_oe \\
  --attention_generation_modes staged \\
  --attention_stages stage2 \\
  --attention_top_p_values 0.23,0.25,0.27 \\
  --masking_probabilities 0.03,0.04,0.05,0.06,0.07 \\
  --num_epochs 5 \\
  --attention_cache_base simplified_oe_experiments/oe_cache \\
  --output_dir sweeps/oe/ablation_best \\
  --extra_args "--attention_filtering_method top_k_avg_elbow_lower"
"""
print(cmd1)
print(f"ì˜ˆìƒ ì‹¤í—˜ ìˆ˜: 3 (top-p) Ã— 5 (masking) Ã— 1 (filter) = 15ê°œ")
print(f"ì˜ˆìƒ ì†Œìš” ì‹œê°„: ~5-6ì‹œê°„ (ì‹¤í—˜ë‹¹ 20ë¶„ ê¸°ì¤€)")

print("\nâœ… ì‹¤í—˜ ì„¸íŠ¸ 2: Stage í™•ì¥ ì‹¤í—˜")
print("-"*80)
cmd2 = """python scripts/run_oe_sweep.py \\
  --dataset 20newsgroups \\
  --mode self_attention_oe \\
  --attention_generation_modes staged \\
  --attention_stages stage2,stage3,both \\
  --attention_top_p_values 0.25 \\
  --masking_probabilities 0.05 \\
  --num_epochs 5 \\
  --attention_cache_base simplified_oe_experiments/oe_cache \\
  --output_dir sweeps/oe/stage_exploration
"""
print(cmd2)
print(f"ì˜ˆìƒ ì‹¤í—˜ ìˆ˜: 3 (stages) Ã— 5 (filters) = 15ê°œ")
print(f"ì˜ˆìƒ ì†Œìš” ì‹œê°„: ~5-6ì‹œê°„")

print("\nâœ… ì‹¤í—˜ ì„¸íŠ¸ 3: Top-k ë„ì… ì‹¤í—˜")
print("-"*80)
cmd3 = """python scripts/run_oe_sweep.py \\
  --dataset 20newsgroups \\
  --mode self_attention_oe \\
  --attention_generation_modes staged \\
  --attention_stages stage2 \\
  --attention_top_p_values 0.25 \\
  --masking_probabilities 0.05 \\
  --attention_top_k_values 3,5,10,20,50 \\
  --num_epochs 5 \\
  --attention_cache_base simplified_oe_experiments/oe_cache \\
  --output_dir sweeps/oe/topk_exploration
"""
print(cmd3)
print(f"ì˜ˆìƒ ì‹¤í—˜ ìˆ˜: 5 (top-k) Ã— 5 (filters) = 25ê°œ")
print(f"ì˜ˆìƒ ì†Œìš” ì‹œê°„: ~8-10ì‹œê°„")

print("\nâœ… ì‹¤í—˜ ì„¸íŠ¸ 4: Loss Weight ì¡°ì •")
print("-"*80)
cmd4 = """python scripts/run_oe_sweep.py \\
  --dataset 20newsgroups \\
  --mode self_attention_oe \\
  --attention_generation_modes staged \\
  --attention_stages stage2 \\
  --attention_top_p_values 0.25 \\
  --masking_probabilities 0.05 \\
  --oe_uniform_loss_weights 0.5,1.0,1.5,2.0 \\
  --self_attention_loss_weights 0.5,1.0,1.5,2.0 \\
  --num_epochs 5 \\
  --attention_cache_base simplified_oe_experiments/oe_cache \\
  --output_dir sweeps/oe/loss_tuning \\
  --extra_args "--attention_filtering_method top_k_avg_elbow_lower"
"""
print(cmd4)
print(f"ì˜ˆìƒ ì‹¤í—˜ ìˆ˜: 4 (oe_weight) Ã— 4 (sa_weight) = 16ê°œ")
print(f"ì˜ˆìƒ ì†Œìš” ì‹œê°„: ~5-6ì‹œê°„")

# ìµœì¢… ì¶”ì²œ
print("\n\n" + "="*80)
print("ã€ìµœì¢… ì¶”ì²œã€‘")
print("="*80)
print("""
1ï¸âƒ£  ì¦‰ì‹œ ì‹¤í–‰ (ìš°ì„ ìˆœìœ„ HIGH):
   â€¢ ì‹¤í—˜ ì„¸íŠ¸ 1: Best Config Ablation (15ê°œ ì‹¤í—˜, ~6ì‹œê°„)
     â†’ 0.83+ AUROC ë‹¬ì„± ê°€ëŠ¥ì„±ì´ ê°€ì¥ ë†’ìŒ

2ï¸âƒ£  ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥ ì‹œ:
   â€¢ ì‹¤í—˜ ì„¸íŠ¸ 1 + ì‹¤í—˜ ì„¸íŠ¸ 2 (Stage Exploration) ë™ì‹œ ì‹¤í–‰
     â†’ ì´ 30ê°œ ì‹¤í—˜, ê°ê° ë…ë¦½ì ì´ë¯€ë¡œ ë³‘ë ¬ ê°€ëŠ¥

3ï¸âƒ£  ë¦¬ì†ŒìŠ¤ ì—¬ìœ  ì‹œ ì¶”ê°€:
   â€¢ ì‹¤í—˜ ì„¸íŠ¸ 3 (Top-k) ë˜ëŠ” ì„¸íŠ¸ 4 (Loss Weight)
     â†’ ë” ë„“ì€ íŒŒë¼ë¯¸í„° ê³µê°„ íƒìƒ‰

4ï¸âƒ£  ì¥ê¸° ì‹¤í—˜:
   â€¢ num_epochs=7 ë˜ëŠ” 10ìœ¼ë¡œ ëª¨ë“  ì‹¤í—˜ ì¬ì‹¤í–‰
     â†’ ìˆ˜ë ´ ì—¬ë¶€ í™•ì¸ ë° ìµœì¢… ì„±ëŠ¥ ìµœì í™”

ğŸ’¡ ê³„ì‚° ë¹„ìš© ëŒ€ë¹„ íš¨ê³¼ê°€ ê°€ì¥ ë†’ì€ ì¡°í•©:
   ì‹¤í—˜ ì„¸íŠ¸ 1 (Best Config Ablation) â†’ 15ê°œ ì‹¤í—˜ìœ¼ë¡œ ìµœëŒ€ íš¨ê³¼
""")

print("\n" + "="*80)

# ì €ì¥
with open('parameter_recommendations.txt', 'w', encoding='utf-8') as f:
    f.write("ì¶”ê°€ ì‹¤í—˜ íŒŒë¼ë¯¸í„° ì œì•ˆ\n")
    f.write("="*80 + "\n\n")
    for rec in recommendations:
        f.write(f"{rec['name']}\n")
        f.write(f"  ìš°ì„ ìˆœìœ„: {rec['priority']}\n")
        f.write(f"  íŒŒë¼ë¯¸í„°: {rec['param']}\n")
        f.write(f"  ê°’: {rec['values']}\n")
        f.write(f"  ê¸°ëŒ€ íš¨ê³¼: {rec['expected_gain']}\n\n")

print("\nâœ“ ì œì•ˆì‚¬í•­ì´ 'parameter_recommendations.txt'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
